{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c1d71b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b3ce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 17:44:23.295956: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-28 17:44:23.296053: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "base_model_name = 'inception' \n",
    "base_model = tf.keras.models.load_model(f'model/{base_model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacffb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = tf.keras.Model(inputs=base_model.inputs, \n",
    "                             outputs=base_model.get_layer(name = 'mixed0').output, \n",
    "                             name=\"local_feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedfd99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = tf.keras.Model(inputs = base_model.inputs, \n",
    "                             outputs=base_model.get_layer(name = 'global_average_pooling2d').output,\n",
    "                             name = 'global_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a47460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_label_weight(df):\n",
    "    labels = list(df['dx'])\n",
    "    \n",
    "    weights = compute_class_weight(class_weight = 'balanced', \n",
    "                         classes = np.unique(labels),\n",
    "                         y = labels)\n",
    "\n",
    "    labels = np.unique(labels)\n",
    "\n",
    "    class_label = {name : idx for idx, name in enumerate(labels)}\n",
    "    weights = {idx : weights[idx] for idx, name in enumerate(labels)}\n",
    "    \n",
    "    return class_label, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277fe0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(img_path, image_size=299):\n",
    "    preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, \n",
    "                                                target_size = (image_size,image_size))\n",
    "    img = tf.keras.utils.img_to_array(img) \n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7edd171",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train_truth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b4490",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label, weights = get_class_label_weight(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c68bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_df = lambda x : x.sample(frac=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_feature(df, label, num = 5):\n",
    "    img_id = df[df['dx'] == label]\n",
    "    img_id = df.sample(num)[['image_id','dx']]\n",
    "    l = []\n",
    "    for row in img_id.iterrows():\n",
    "        row = row[1]\n",
    "        path = f'data/train/{row[\"dx\"]}/{row[\"image_id\"]}.jpg'\n",
    "        l.append(get_img(path))\n",
    "    return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05641177",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Causal_Model(tf.keras.Model):\n",
    "    def __init__(self, num_classes=7, class_weights=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # Class Weight\n",
    "        self.class_weights = class_weights \n",
    "        \n",
    "        # Pooling for local features for each image\n",
    "        self.pooled = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "        # Post-Concatenation\n",
    "        self.dense_1 = tf.keras.layers.Dense(1024, activation='relu')\n",
    "        self.dense_2 = tf.keras.layers.Dense(1024, activation='relu')\n",
    "\n",
    "        # Prediction Layer\n",
    "        self.prediction = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    \n",
    "    def call(self, global_feature, local_feature):\n",
    "        local_feature = self.pooled(local_feature)\n",
    "        x = tf.concat([global_feature, local_feature], 1)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.prediction(x)\n",
    "        return tf.math.reduce_mean(x, axis = 0)\n",
    "    \n",
    "    def build_graph(self, local_feature_shape = (35, 35, 256), global_feature_shape = (2048)):\n",
    "        local_feature = tf.keras.layers.Input(shape = local_feature_shape, dtype='float32')\n",
    "        global_feature = tf.keras.layers.Input(shape = global_feature_shape)\n",
    "        \n",
    "        return tf.keras.Model(inputs=[global_feature, local_feature], \n",
    "                              outputs=self.call(global_feature, local_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba7423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = Causal_Model()\n",
    "cm.build_graph().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = True\n",
    "model_name = 'causal'\n",
    "if retrain and model_name in os.listdir('model'):\n",
    "    model_weights = tf.keras.models.load_model(f'model/{model_name}')\n",
    "    cm.set_weights(model_weights.get_weights()) \n",
    "    cm.build_graph().summary()\n",
    "    print('loaded previous model weights...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc23813",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a96bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loss_model(model, global_feature, local_feature, y, class_weight, training=False):\n",
    "    y_pred = model(global_feature, local_feature, training=training)\n",
    "    loss = loss_object(y, y_pred, sample_weight=class_weight)\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def grad_cm(model, global_feature, local_feature, y, class_weight):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_model(model, global_feature, local_feature, y, class_weight, training=True)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8e1601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_local_feature(df, folder,  num = 5):\n",
    "    img_id = df.sample(num)['image_id']\n",
    "    l = []\n",
    "    for img in img_id:\n",
    "        path = f'data/{folder}/{img}.jpg'\n",
    "        l.append(get_img(path))\n",
    "    return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382888b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_tensor(arr, repeat):\n",
    "    return tf.repeat(arr, repeats = repeat, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_acc(cm, test_df, folder, end = \" \", num = 5):\n",
    "\n",
    "    acc = 0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for row in test_df.iterrows():\n",
    "        row = row[1]\n",
    "\n",
    "        img_path = row['image_id']\n",
    "        img = get_img(f'data/{folder}/{img_path}.jpg').reshape(-1, 299,299, 3)\n",
    "\n",
    "        label = class_label[row['dx']]\n",
    "\n",
    "        global_feature = global_model(img)\n",
    "        global_feature = repeat_tensor(global_feature, [num])\n",
    "\n",
    "        local_feature = local_model(get_test_local_feature(test_df, folder, num = num))\n",
    "        pred = np.argmax(cm(global_feature, local_feature))    \n",
    "\n",
    "        y_true.append(label)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "        if pred == label:\n",
    "            acc += 1\n",
    "\n",
    "    print('[Acc] : ', (acc/len(test_df)), end = end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('data/val_truth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0227d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 11)\n",
    "num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac0e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(epochs, desc='Epochs'):\n",
    "    loss, steps = 0, 0 \n",
    "    df = shuffle_df(train_df)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    for row in tqdm(df.iterrows(), total=len(df)):\n",
    "        row = row[1]\n",
    "        \n",
    "        img_id = row['image_id']\n",
    "        label = row['dx']\n",
    "        \n",
    "        img_path = f'data/train/{label}/{img_id}.jpg'\n",
    "        img = get_img(img_path).reshape(-1, 299,299, 3)\n",
    "        \n",
    "        global_feature = global_model(img)\n",
    "        global_feature = repeat_tensor(global_feature, [num])\n",
    "        \n",
    "        local_feature = local_model(get_local_feature(train_df, label, num = num))\n",
    "        \n",
    "        label_idx = np.array([class_label[label]])        \n",
    "        weight = np.array([weights[label_idx[0]]])\n",
    "\n",
    "        loss_value, grads = grad_cm(cm, global_feature, local_feature, label_idx, weight)\n",
    "        optimizer.apply_gradients(zip(grads, cm.trainable_weights))   \n",
    "        \n",
    "        loss += loss_value.numpy()\n",
    "        steps += 1\n",
    "    \n",
    "    print(f\"[{epoch}] Loss : {loss/steps}\", end = \" \")\n",
    "    if epoch % 5 == 0:\n",
    "        cm.save('model/causal')\n",
    "    if epoch > 5 and epochs % 2 == 0:\n",
    "        get_val_acc(cm, val_df, 'val')\n",
    "    print(f\"[Time] : {time.time() - t1} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4715abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test_truth.csv')\n",
    "\n",
    "acc = 0\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "for row in tqdm(test_df.iterrows()):\n",
    "    row = row[1]\n",
    "    \n",
    "    img_path = row['image_id']\n",
    "    img = get_img(f'data/test/{img_path}.jpg').reshape(-1, 299,299, 3)\n",
    "\n",
    "    label = class_label[row['dx']]\n",
    "    \n",
    "    global_feature = global_model(img)\n",
    "    global_feature = repeat_tensor(global_feature, [num])\n",
    "    \n",
    "    local_feature = local_model(get_test_local_feature(test_df, \"test\", num = num))\n",
    "    pred = np.argmax(cm(global_feature, local_feature))    \n",
    "    \n",
    "    y_true.append(label)\n",
    "    y_pred.append(pred)\n",
    "    \n",
    "    if pred == label:\n",
    "        acc += 1\n",
    "    \n",
    "print('Acc : ', (acc/len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_acc(train_df, cm, num=15):\n",
    "    acc = 0\n",
    "    for row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "        row = row[1]\n",
    "\n",
    "        img_path = row['image_id']\n",
    "        label = row['dx']\n",
    "\n",
    "        img = get_img(f'data/train/{label}/{img_path}.jpg').reshape(-1, 299,299, 3)\n",
    "\n",
    "        global_feature = global_model(img)\n",
    "        global_feature = repeat_tensor(global_feature, [num])\n",
    "\n",
    "        local_feature = local_model(get_local_feature(train_df, row[\"dx\"]))\n",
    "        pred = np.argmax(cm(global_feature, local_feature))    \n",
    "\n",
    "        if pred == class_label[label]:\n",
    "            acc += 1\n",
    "\n",
    "    print('Acc : ', (acc/len(train_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels = list(class_label.keys()))\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d24c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train_acc(train_df, cm, num=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
